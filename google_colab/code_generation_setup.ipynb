{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "3389c645"
   },
   "source": [
    "# Set Up for running experiments on Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "f223b665"
   },
   "source": [
    "#### Step 1: Start by importing the .env file\n",
    "\n",
    "Ensure that you have the fields filled in \"mongoDB_uri\", \"collab_token\", \"GITHUB_USERNAME\", \"GITHUB_BRANCH_NAME\" and \"GITHUB_PAT\" filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "73e1f2b2",
    "outputId": "0ce410d7-34ae-4d4e-e24c-d1cb3d62c84a"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "45caaa9e"
   },
   "source": [
    "#### Step 2: Install python-dotenv package and load the dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "767b326a",
    "outputId": "b516315d-54fb-4746-c37c-8365879af01c"
   },
   "outputs": [],
   "source": [
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e04dab6b",
    "outputId": "4c55bd08-8357-4d05-b98d-f89506a06e1a"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "9213c5c0"
   },
   "source": [
    "#### Step 3: Cloning the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f9c754f",
    "outputId": "a5029ce9-2abe-4dff-9747-4739b2bd39b9"
   },
   "outputs": [],
   "source": "# 1) Paste your GitHub PAT securely (no echo in output)\nimport os, subprocess\n\nGITHUB_USER = os.getenv('GITHUB_USERNAME')\nGITHUB_BRANCH_NAME = os.getenv(\"GITHUB_BRANCH_NAME\")\n\nos.environ[\"GH_TOKEN\"] = os.getenv(\"GITHUB_PAT\")\n\n# 2) Clone the specific branch (hide output so token isn't printed)\nurl = f\"https://{GITHUB_USER}:{os.environ['GH_TOKEN']}@github.com/your-org/your-repo.git\"\ncmd = [\"git\",\"clone\",\"-b\", GITHUB_BRANCH_NAME, \"--single-branch\", \"--depth\",\"1\", url]\nsubprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n\n# # 3) (Optional) Remove token from the saved remote to avoid accidental leaks\n# import pathlib, shlex, json\n# repo_dir = pathlib.Path(REPO)\n# subprocess.run([\"git\",\"-C\", str(repo_dir), \"remote\",\"set-url\",\"origin\",\n#                 f\"https://github.com/{GH_USER}/{REPO}.git\"], check=True)"
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "57fa6f5d"
   },
   "source": [
    "#### Step 4: Change directory to the cloned Github Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1896038",
    "outputId": "61d98f89-1653-455a-a575-bb16c8a7dc78"
   },
   "outputs": [],
   "source": "%cd {\"your-repo\"}"
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "2d76a4d9"
   },
   "source": [
    "#### Step 5: Pip install the necessary packages from requirements-colab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55c7177f",
    "outputId": "f96a7bde-2fe1-4395-d18b-0a7ab9a5d2a7"
   },
   "outputs": [],
   "source": [
    "! pip install -r requirements-colab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "04596637"
   },
   "source": [
    "#### Step 6: Login into HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "5a09600c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = os.getenv('collab_token')\n",
    "\n",
    "# Login to Hugging Face\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "080aea75"
   },
   "source": [
    "#### Step 7: Downloading the desired model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401,
     "referenced_widgets": [
      "5398f3ab2f60434b886553412067895c",
      "1d0fbf3d09b643b998d2487b1ee9f154",
      "c99b806bb1a94fcfb0ec1f9b81ecc675",
      "4772961ba9834247981f45b83eb3fe73",
      "02ecf1d7ff6d4a779006f892de94ae18",
      "cc31572e5b6041069ebabadaf6c669ac",
      "3331b70cab944faabbd13a62445dbca8",
      "c5cc4fae214e4dcea656d724a7a8ef8f",
      "37de48e6c81e4f098f5cd1ea9aeb0a55",
      "4487a1fd74cf401fb3a74403c269dce4",
      "825d1ad11c404a13b040ac1d96bc62e4",
      "a70c398af47a4881b6d1952ccf4e5b7c",
      "76a969a174af41e6a9a67647b95c7eeb",
      "1da8a454bee44043a5e0474d202b8d5c",
      "9d820b538c07441fb119147c0378f87f",
      "392e1d868a464d4b84114da639f56484",
      "dfb8d0c7bbdb4385be880fb74dc4a6ef",
      "d8afdedd46e2404bbb053fbf56399041",
      "3fa308e2cedc4b3dbcf1ceb159d17039",
      "1b22ecff3b1e44b781f2b7d5b8e3bc80",
      "a735e13e571f458aaf0c6768c7efe0a6",
      "05e40246e0bf427ea4c451cc5609c5a7",
      "1a460e217ac04ff6a7e92fdf2ed6f885",
      "13e1649b35ef486dbbf2e8bb6abfbe6e",
      "57d09665c8614ed9a180c03cba46dcc5",
      "a8b6e0e039884a8b9ed55f0a901b287d",
      "5f57eecdcae343a99dc46be49f7e6c0c",
      "efb60a94b0d34a97bf94b1dfe8357a37",
      "f9a0fccaaf094f63ab5b3437fb9019bd",
      "0d88ce708e8b4d8da0989bd42d0316a1",
      "261b103151294d1eb58a9c43ae5084ad",
      "4cb12a4885bd49d1a051321a2273018b",
      "9bd72ce6a671410f89c9ccd6aef612c2",
      "032946d1d25743f4a92223eaa746f323",
      "4e12b419bbdf4ff78b9ac987d79a0b71",
      "8c704afc4f6645389ebea31b396f5464",
      "13c4fa1c34914d97b9f6c14b3465f4c4",
      "4ce66947c36147ae9b44a30826cb902d",
      "c37085611f4b4dc29617587c69eace3b",
      "76e8591221dc4f05919d3c2bd0a304f4",
      "34460bac4ce549c7b9214ea59d526607",
      "6b6eb7f8f42a4f3a875e3c588b1d580e",
      "ebd841ed8b114b759b04349860766984",
      "d62bf3552c3a49dba650142d08928e0e",
      "9d0fbef3b98848ab88e34ea4c01c4a31",
      "05d4749705be4a0082cf216414ac95ff",
      "83f7156a6bfa41e2aaaca66c922eec31",
      "fe88439c855d488898cd0ab9ba9ca51a",
      "d6b518d742a849c7b8aa89cdfcbfef5d",
      "9b012613b95e46658071aa63aea22d38",
      "10d16d535b6e45c6ada70c5d103acc9a",
      "8ac63e9cf8cb40ecad648ca412af20e2",
      "172bf8eb40354c19beedbf4da336e163",
      "dee9a12f0bae4f54893f86035b5fc7d3",
      "269e804decb9409789d0e1f74b6e3031",
      "03acf4390dfd4d3c84a98dc22e3a0259",
      "6b8cd6c434aa4c5daf341c2a54a7fc41",
      "dcf12f12320c418e90fa076a813c1ffa",
      "b3cbc31c67f140308496ac34a4f74285",
      "4005e08ceb264308b57d926edceca436",
      "3bd4335d1f0c44a0b9955de006be875a",
      "78a95446959e430385b31f5642890c91",
      "6f69b622ba1942acb895e4625b58c865",
      "9d2ea967b7bf446483c9de3de2a6b0e2",
      "4c92c93944294de590c8be325e42a696",
      "8f834a0ed1df4b63a137f430ebf4f982",
      "e726e97745d14e86aa678c687b6a89f6",
      "63cff1646f42416d9c32246d7f9845b2",
      "fb1729d11d8b418c887eaab10fe84e4a",
      "9fea7f0d0ba5481eb17ce47fbee09e58",
      "cb1a3c81cdae4f19b9bf43a652e7a3f6",
      "cbee9256d466464cb1407f12d200858b",
      "9a39787a9ddb486781cee4544394cefd",
      "70b4a4ffca8646c29fdc0637d2b51e7d",
      "1159ea5f9df3493395aeca53668d5f2b",
      "ff30f90759024a90a8306591f828b050",
      "ef2c4a01a0ef46a18a9b71d1042fb7e1",
      "f5c76e3b880c4b9a9d67e6b5b5a42e59",
      "3ead182c43454fda8bfc7ed955ccdbed",
      "78db0d0b314748d695659a65521ecb8a",
      "6b28d970bcc44f47b0b2737ea9d202fb",
      "963ef2804bfe4761956ff29de3061fde",
      "e4df9e7731df4b78b7c76fb27052b989",
      "6e3eec2286b54363b043e57e6dd6b2c3",
      "26eb9537d9e249fbb857935b4dd151d6",
      "b35c26bb488545bea209c7a792c0ac41",
      "113ab00a60ce40b4aca18f9d5602cff8",
      "ec841da653af40ea945cf881aa13f5df",
      "5e75fe8a6a81432888889478e54cb316",
      "b6be12128af043b6a7f9c45b636b0a80",
      "d98c3c6aeb374e3c94a00a707fbb4e6c",
      "c1618b54dcb34c609ba6d0c53c25865b",
      "f04be2221a9941aeafbbd78d7e17f0b7",
      "ccae5113231143fb8393c01f6e7dff91",
      "df8342f8db2b441481550e9daa60ab43",
      "03feecd89e5c4ea1b791e5314173e233",
      "3edf33c983a94c4f9f8c86b49e577679",
      "1c9b46cadcd345f3b9b01e3bc32302e7",
      "4f7de7cbaa6540e2bc0ca1bdbed6e471",
      "953c9d48d21b482d83d6cd6bc47ab7d3",
      "dd478b8c62fe4cf8a94b71e98c8e2757",
      "7bba44a60b5c40828ac9ed5ab51aed02",
      "e8f1985f2f7f487c9b12ce12b251fab0",
      "177dde9743ec477db9fceb0e4a1c55da",
      "b909a2b134c74ab1b90f2d2766bdd6ea",
      "1ad906e15c6c4ee0b8e8b24c7c21a46b",
      "24a4bbf7bb5343b191482e4b9f411680",
      "888f8cdf44fb4c118c17853b66eb7fbb",
      "a9bd246ef6b44e9a9f372d43ee5163cc",
      "820b970e0556466393ced840eb8761f9",
      "9a6f6665dc5941d7a35e93c3484dc278",
      "904170c8a61c4e30b806c920293466cb",
      "951b7d38d9a843c5bc89e69306a83bfe",
      "be8dc82b6c8b41ba862dd38b74b071ee",
      "669c103a93d347459884b7fc0addf9c8",
      "ca5b9983c0cc484b9d9e8804c6d5173d",
      "755e8b79c0644aa39f41ef14f202030e",
      "c01822ad4e494af69d4ea0bc667fc121",
      "a85661dca3614cc9bc52e8c3e1e1067a",
      "f18e94fb3cbf46adad228ac3b2f77d38",
      "c8d451a9658e4b05b8d17bc6e25485fd",
      "03ae61f45db0445d876539162d6dfd81",
      "fe0f53741f1c4d358b036f4b3179dd44",
      "d6ce666bc72945ada64fe168ccea03c7",
      "62be8ac0397649b2b310a26daf3c6333",
      "8a810d5839c24cddb5bd33edc59f48f4",
      "88844e7468ce4d22b1cce25ba598ba78",
      "ca101810ebbe4c6abd26f1e57cf8bb07",
      "0902a77e0ab840568f57799ce358dd7a",
      "973163bc5d1a4dbca61860bc137f37e9",
      "9857085814244e638f3531c1bbda9203",
      "a67a60e36d264b3b9cfc76d7256c7d67"
     ]
    },
    "id": "2c5ed89c",
    "outputId": "cd809b37-9bed-4b7e-cc38-aa9f56d95c92"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "6343e390"
   },
   "source": [
    "#### Step 8: Ensuring that the model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8aKn4Y2LX-m",
    "outputId": "93403e2f-85d1-46ec-e38c-69f7cdf931a1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "\n",
    "# test prompt\n",
    "prompt = \"The capital of France is\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=20,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "decoded_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded_text)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "bd21a2f5"
   },
   "source": [
    "## FROM THIS STEP ON, COPY AND PASTE WHATEVER EXPERIMENT CELLS YOU NEED.\n",
    "\n",
    "Do remember to do this step first before uploading into Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "370e65c5"
   },
   "source": [
    "## LLM Consistency Testing with Mistral LLM\n",
    "\n",
    "This notebook contains code for testing code inconsistency in Mistral LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "9eff811c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "847501b0"
   },
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(curr_dir)\n",
    "proj_dir = os.path.dirname(parent_dir)\n",
    "sys.path.append(proj_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "60fab327"
   },
   "outputs": [],
   "source": [
    "from code_generation.code_generation_tester import CodeGenerationTester\n",
    "from code_generation.prompt_templates.prompt_template import OpenEndedPromptTemplate\n",
    "from utility.constants import BigCodeBench, HumanEval, LexicalMutations, SyntacticMutations, LogicalMutations, PromptTypes, CodeGeneration, ReasoningModels, NonReasoningModels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "9cc57730"
   },
   "source": [
    "# Declaring constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "76fd1f92"
   },
   "outputs": [],
   "source": [
    "## Declaring Prompt Type Constants\n",
    "ZERO_SHOT = PromptTypes.ZERO_SHOT\n",
    "ONE_SHOT = PromptTypes.ONE_SHOT\n",
    "FEW_SHOT = PromptTypes.FEW_SHOT\n",
    "\n",
    "## Declaring Mutation Constants\n",
    "RANDOM_MUTATION = LexicalMutations.RANDOM\n",
    "SEQUENTIAL_MUTATION = LexicalMutations.SEQUENTIAL\n",
    "LITERAL_FORMAT = LexicalMutations.LITERAL_FORMAT\n",
    "\n",
    "## Declaring Benchmark Name Constants\n",
    "BIGCODEBENCH = BigCodeBench.NAME\n",
    "HUMANEVAL = HumanEval.NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XLw_wNT51KwW",
    "outputId": "598211e9-44dc-4ccf-e79e-428f0af933b8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU memory before running the test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Check available memory\n",
    "print(f\"Available GPU memory: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnTjaleVgEeq",
    "outputId": "39b08d3c-dd0e-45b5-8379-d6040d6f8640"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656,
     "referenced_widgets": [
      "20db32bdc67c4f378defd84a4e05dd27",
      "a0b64cd99e664bf38073916034834079",
      "2de9525bc6ff40b3881e9951695116f7",
      "99bf1cd2d4154c31af434d72e9cea10d",
      "86dce07054d14f21a23b5890f7330977",
      "1c24bbc12d594871b33d1d0fba982087",
      "e878df57debd4c0eb953c83efe7e8b94",
      "35fe7932addd4458a7eeb5484a8fcfd7",
      "297a716105454a66bdfe5eeb2a249107",
      "0fa52b69bd714d088f3f72c82949dfc4",
      "ed8ce1875ab04553b694caa11627c75e",
      "3a1bd0d7be0445259d21caeacc3288b3",
      "f443ad129a154d71a9351b0d0f90255d",
      "1a1244cddbdc488bbfbcdb635b160e9a",
      "f2731738eebd47caa376c2312977b364",
      "316b5858d0dc4443a4c491cc27f9b7ad",
      "d1fa77f8d7634204a7b45ae7c75b3e7f",
      "e0a9184c0f22405f9e248e628e63ef1f",
      "d346b67b4aa0415882f922df53b05b3f",
      "65de88f412ff49bcb79ed62238070ac0",
      "dcd96ab82b7b4f63a9665d19bfea0c29",
      "6e724292331d42b28c69c1319fc423b6",
      "3f4184dc95fb447d897a5773fa0173af",
      "06e13f66c7e646e2a4c62b3013db4a3c",
      "648b50761abb41618336cfd968397cdc",
      "a476fa7710f144728d570564485a7915",
      "bdbb7989b7c446dd9d25a1e76aa5d219",
      "404a71ebb2cf484884ac116b2599e652",
      "66d2b39b66e64175a8df833e3857a2b2",
      "39bf0c302b9241feb0b841d7df858a42",
      "ebc743f98cbe4f6ba7f21dca322556e6",
      "513ea993b6cd4335b934b4ecef5bfc91",
      "5bde55d166af498d8c4b54de48f33dec",
      "46949c11ead04ec1b8e8a806733f34f8",
      "8bc867011b4540809ada9f1e9645d053",
      "7638a047d76941e79695bff6117a41d0",
      "f61ee2c14e42450cb0c63bc052f19ca8",
      "b00e6820c9e943e393298b644e146f9d",
      "42433add5ea9491f8fbf783ea688c361",
      "c509a3e69ea94493af24cc1f07ec8e9d",
      "48f863207d674562b193ba7f7b544375",
      "e5c272796ffc4082b833bfd6ec938a83",
      "a1166bd6ab194dadb4ae554a274cd7f3",
      "5bc3f39c6f824fe2b79ecfef0dc92612",
      "160830994d2f4f44ae05c0a1d871781e",
      "3424c98e3b584584bda9eef08e110c7b",
      "22f41ca71e9e46619e436eae50801bc5",
      "eabd2a3c0fd548d5a1978a32e2cf047b",
      "653c1fe7c171450d90742e6c0a235f9a",
      "93fdcc1496474002bbf2476f08e9098b",
      "b1e570fc8186471bb732add2bcda6243",
      "78553b193de74dc0a04ae66edcdc6db2",
      "99dbf3b2a8dc43108cdb4ff83233ae2e",
      "9a642d038eb0416d8cc796730487e5fb",
      "1b3468b57c6743cb8b5bfcf07eb133de",
      "ad35901b05dc424fa89339e62ed38c98",
      "96d1953b67314b33bd8f382b57ac3e6f",
      "6f871abf47fa4ed7acb3135627978bf7",
      "7ffda59d15c643f9b763d0dfe593cbb1",
      "5a990af53cf942cfa15119cd6d72a00a",
      "607b04977984411e93b9419a3ea4e945",
      "8903c5ac7cf9425fbc65273e81a01b8b",
      "0007f161fa02454190c449f771fddefd",
      "b07e36410f604255a9ad772a0f7bcf6e",
      "c4bc012703fe4886a278f75ebaaeed28",
      "7e13d1d6897944b7988e6dd1a18c9cf6",
      "c78caee7af91470082e7cc513d0c927d",
      "325759869b30491d9cb4b30de5117593",
      "993460b0bad94c31862e9a31ef5702fb",
      "774edae1ecad4fdd995503807b6598b8",
      "4d4fb72006cb48759be986f4250a4fcd",
      "018952bc6de64062bdf3d4dc2f740549",
      "e8d677771e2e4d90b8c529db3c81b86f",
      "78a8e4fb68574da89fe1714a6fab5aff",
      "d934c60af1224545a0c7bc5b43fbd9e4",
      "107b2edd9df64a70996966da72696862",
      "839aa33821e24e9bb3550f2a307ce896",
      "37c727479cd4401eb0f2edaa19378d12",
      "6df172446d7341b8828f6426235d6ea7",
      "901ade3171ff408a8ddbb7bf80f6f70c",
      "2c4ba10b06cd4139b993196f8c7b2d79",
      "ede50b8def3e49b3af1d0693d1239712",
      "10815ee74dbb4b6cae8d8347050b8ea3",
      "3ff822f0123f45faaeed2ebe998316b7",
      "38ca0f1c00c847d5bc552d80f4039021",
      "f38109cde69e45939f03bed7ab8bf8c4",
      "b89b204987c64b03970244286afdfb88",
      "16b77b18de024ee3900ebce384901969",
      "5a9af67bd77a4e0e9640f2cd098e4c71",
      "377fb57526214d35adb16157a7bbdceb",
      "963f6b3e92a34cd7aff39e0a33d519ec",
      "beb616ca497d4844bf49efba7121f804",
      "979be736ec8b4897939410ac30c02ac6",
      "9db34081fe074600aaa26918489b447c",
      "e08a745bca324118aff04603ef318f78",
      "e7754807f14249a0997c737cbb7a828b",
      "aa3af6956f9f48188c390e2049134d62",
      "e6a8bac8f13444a2b7c1571131d97d39",
      "636bdc7a8af24a50b20916e71749994c",
      "c2470d0da803418aa9cc9155538b6cb4",
      "eab81aea05874feaa22f08b2ed2537cc",
      "be73b938124644cab262006574bd01d6",
      "ed329feab934403c9a2138b5478405ef",
      "1bcb619ac09b4f2cbf0186c957043537",
      "1770ce0be3d64e3e9be5776e73546e2d",
      "05ea05716d5d4224b6c80a045821322b",
      "50f9176ce3684ef392aedbc6d9747297",
      "a9247c74090944abb1816064d02cdfad",
      "3cef028f0c93442e9ea72272c94f49c4",
      "d17d3603dd53418e8421bfbd740d8ea0",
      "36ddd6911a4b41d99bbbf026c1971cc7",
      "a4dbbe0b1dea450a8971a552b4752e91",
      "e57e0734ace5496097571f13f0bf0193",
      "3b000b959c6d4c2aaf47427523fd5158",
      "27c84e201ba74da088bd5c2dd4d021d1",
      "56d1c0b23c9848b59d3b760fccb28fef",
      "91c1a8fb1aaf45aaaf8f348de627f0b6",
      "aa0f083542d542dbb6800a9dfe00a8df",
      "d04f13d2b64346a99cc294a47b8b11ee",
      "2c1d7c9ae1b240e790edee9866fc8c95",
      "338da0359d2f4efc94c739d6ecd62ee4",
      "6660e2a2526544218c7311e8657816e9",
      "3cb3cc56acb340388cd8413ce8196d49",
      "f15bd736e8894b5b80e6163fae0247af",
      "08a391fc5dc348239816c08738a83186",
      "f411a0f6fc0e4059802f589debcbdd14",
      "4f37ecfb5cb24748a75f1fc91a5ca50b",
      "4f864ec276a849c080baae3c7703b73c",
      "0a758f6ed5c94cf898fc1dc6d393a02f",
      "8aa1da3f56c14fa6a8d647d1b31952ab",
      "a01bb442f46840b5a691f39a1e5714b8",
      "26eef40eaf4740a384e0d205ee0afba7"
     ]
    },
    "id": "6p7dvxaJppve",
    "outputId": "614c7fa3-cf7f-494a-c2f6-57157b697e8c"
   },
   "outputs": [],
   "source": "import os\nimport shutil\nimport subprocess\n\nprompt_type = FEW_SHOT\nmodel_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n\ntask_set = HUMANEVAL\n\ntry:\n    llmtester = CodeGenerationTester(f\"{task_set}_Code_Generation\")\nexcept Exception as e:\n    print(f'llmtester could not launch due to the following error: {e}')\n\n\nresults_base_dir = os.path.join(proj_dir, f'results/code_generation/{model_name}')\nos.makedirs(results_base_dir, exist_ok=True)\n\nmutation_configs = [\n    [],\n    [RANDOM_MUTATION],\n    [SEQUENTIAL_MUTATION],\n]\n\nfor mutations in mutation_configs:\n    mutation_str = \"_\".join(mutations) if mutations else \"no_mutation\"\n\n    output_file_path = os.path.join(results_base_dir, f\"Llama_Final_Runs_{task_set}_{prompt_type}_{mutation_str}.csv\")\n    drive_dst_dir = os.path.join(f\"/content/drive/MyDrive/your-repo/code_generation/\", model_name)\n    drive_dst = os.path.join(drive_dst_dir, f\"Llama_Final_Runs_{task_set}_{prompt_type}_{mutation_str}.csv\")\n\n    # Ensure Drive folder exists\n    os.makedirs(drive_dst_dir, exist_ok=True)\n\n    # Run experiment\n    llmtester.run_code_generation_test(\n    prompt_helper = OpenEndedPromptTemplate.return_model_appropriate_prompt(prompt_type, model_name),\n    num_tests=llmtester.question_database.count_documents({}),\n    mutations = mutations,\n    prompt_type= prompt_type,\n    output_file_path=output_file_path,\n    task_set = task_set,\n)\n\n    # Overwrite results on Drive\n    shutil.copy(output_file_path, drive_dst)\n    print(f\"Saved {mutation_str} results to Drive\")"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}