{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "3389c645"
   },
   "source": [
    "# Set Up for running experiments on Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "f223b665"
   },
   "source": [
    "#### Step 1: Start by importing the .env file\n",
    "\n",
    "Ensure that you have the fields filled in \"mongoDB_uri\", \"collab_token\", \"GITHUB_USERNAME\", \"GITHUB_BRANCH_NAME\" and \"GITHUB_PAT\" filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "73e1f2b2",
    "outputId": "585617d2-0674-47d0-bcd7-d1e29baa82e2"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "45caaa9e"
   },
   "source": [
    "#### Step 2: Install python-dotenv package and load the dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "8-hT9lx4IQ_E"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "767b326a",
    "outputId": "e68ece89-018b-49c0-ef92-bccb5cd26913"
   },
   "outputs": [],
   "source": [
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e04dab6b",
    "outputId": "ab56d215-da56-4629-8e24-da979cd466ca"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "9213c5c0"
   },
   "source": [
    "#### Step 3: Cloning the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f9c754f",
    "outputId": "db788162-d224-4e13-afb6-e484c4e0f85e"
   },
   "outputs": [],
   "source": "# 1) Paste your GitHub PAT securely (no echo in output)\nimport os, subprocess\n\nGITHUB_USER = os.getenv('GITHUB_USERNAME')\nGITHUB_BRANCH_NAME = os.getenv(\"GITHUB_BRANCH_NAME\")\n\nos.environ[\"GH_TOKEN\"] = os.getenv(\"GITHUB_PAT\")\n\n# 2) Clone the specific branch (hide output so token isn't printed)\nurl = f\"https://{GITHUB_USER}:{os.environ['GH_TOKEN']}@github.com/your-org/your-repo.git\"\ncmd = [\"git\",\"clone\",\"-b\", GITHUB_BRANCH_NAME, \"--single-branch\", \"--depth\",\"1\", url]\nsubprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n\n# # 3) (Optional) Remove token from the saved remote to avoid accidental leaks\n# import pathlib, shlex, json\n# repo_dir = pathlib.Path(REPO)\n# subprocess.run([\"git\",\"-C\", str(repo_dir), \"remote\",\"set-url\",\"origin\",\n#                 f\"https://github.com/{GH_USER}/{REPO}.git\"], check=True)"
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "57fa6f5d"
   },
   "source": [
    "#### Step 4: Change directory to the cloned Github Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1896038",
    "outputId": "b205aa0c-3f96-45ee-eb50-eff47872983e"
   },
   "outputs": [],
   "source": "%cd {\"your-repo\"}"
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "UzgTCwTL4o-L"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "2d76a4d9"
   },
   "source": [
    "#### Step 5: Pip install the necessary packages from requirements-colab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "55c7177f",
    "outputId": "dea96dec-82f8-4605-8443-5174fa7ec19b"
   },
   "outputs": [],
   "source": [
    "! pip install -r requirements-colab-big-code-bench.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "04596637"
   },
   "source": [
    "#### Step 6: Login into HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "id": "5a09600c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = os.getenv('collab_token')\n",
    "\n",
    "# Login to Hugging Face\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "lo9f7yha_iFp"
   },
   "outputs": [],
   "source": [
    "#!rm -rf /root/.cache/huggingface/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "id": "080aea75"
   },
   "source": [
    "#### Step 7: Downloading the desired model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkjEd205ECQ3",
    "outputId": "27ab235e-7dac-4877-c94a-831de08d10a1"
   },
   "outputs": [],
   "source": [
    "  pip uninstall numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "jgUbCL_tEKRn",
    "outputId": "643a2746-d424-4857-b031-a678a28e0c25"
   },
   "outputs": [],
   "source": [
    "  pip install \"numpy>=1.24.0,<2.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "c10e6d44d1544372a51c2463f337b203",
      "2f5f00a991a3431aa7410879de1707de",
      "8e52153cb2cd41ae98b36a4c8e467836",
      "74799358c31e4bb898ce588da5696f39",
      "b9a5b9cc16404eb7b356e3772a2291bc",
      "4d111de7147543e69aa357dc372c8fa7",
      "3e885a793c854748a2d0c914b202b3db",
      "2417da19df6647a1b91e7218b6bf3ad6",
      "a14d91e8b7b8499ca7fa5449743eb800",
      "1f8a1cb7b4004d80bd3cf7807470ef5b",
      "943d580907b546648829f250d7cab6d2",
      "a7e1c596ffa9459f8cfdc529c16396f8",
      "a0656387c3b344388328128add031a06",
      "9271192a08274c16ab2138020111c173",
      "4e1cba52be7142ee8a168151a95e14fa",
      "66a77d181ac94513a75868f2ccb30a5e",
      "00ed848e432a43038a3815cba8eb73d5",
      "4988745fc787423981b4bd2bbe8e4456",
      "2dbbbd833cc347dbb0ec337647053e20",
      "3c97e61e70b24f58aa06876ef7c51e71",
      "3ad7f0abe74d488b873ab22f967ac836",
      "21e77013c83b44d082cc249580244523",
      "e7751dde68074d86bedf7eeb5361211a",
      "25558494759e47189cce43cd9b263eb5",
      "2c6f53917b3d41ad8f8938268c1f38be",
      "37f48a238ab74f64b5885ee196100775",
      "612a9556a75b413ea8d1bb4c944cb4b0",
      "01abbbd8bcc14cfc82e8a36d81b7e44d",
      "66bc2e92aa2b4fcd82b4e0f7d28a6c28",
      "8fc34ff5b5004437b816b4a6fd0b8677",
      "1166bb5bcfa24e43add2616374f118ea",
      "b1a63a8c8c374934a4de9495f893ee99",
      "0021ec081f334581b9a4bc2a7f153101",
      "c6818e2d6ad44621ba3679b369e82fdf",
      "9918fa2e7e874a579ecf3cd204beb813",
      "f51273f208c142e68542ab42110be2df",
      "81ca93ed27194544a8fcfc26bc911c6f",
      "c6b99940aad84a8a873995913da2c951",
      "3c184d75881f4634862d1fac5956b43a",
      "f30e6bf3bc3a4357a1816f884db76811",
      "ff11e120944e4aacae5f41dbbb2736c1",
      "41b406c4f19f453b8fed34e4b446d46a",
      "6fafdbb4aa124d2dbb6f24241783a0c9",
      "a2e92e2521214b309fc48f556098f31f",
      "84a2ed0a5d9747af8c0f9558ea665b91",
      "2ff72c4320e9401789671b710b68fb4d",
      "a2439f27a64e4929b109af18e4823528",
      "82268dd655ab4ffca52337aad5222b03",
      "4234bd78d65748c49621867860e373b3",
      "bcfe4cd91cf0423a92ab473d853b3a34",
      "d9c131d47c8945ecbb2550f7ae975c58",
      "888b6bc9f7b94168a502ded691ce6707",
      "c84ffb43e67249b885cab0217d10fe42",
      "5f7beaa2a2104983a347ed423377f957",
      "0ca68e10dc864a02a4b8e0411cd4e815",
      "39831d09cf734a3f9d7cd23279afd04c",
      "dcf40377ef974a9bb42a29180b32e5fc",
      "f28166cfa6154c8ab75247eda29aea68",
      "08281e50cc664924b32ffb72307cece5",
      "652078f1f66f418c9eb14c753323f500",
      "db564b25dd3d4ba0853f8d279c8c4696",
      "21b32b81fcd24c8494148fc1f952df3a",
      "648d87cb789f4521afd42a2daab8bec0",
      "7e0332813c104ac08707c26883293e0a",
      "95b7304643aa4e8ab74a410861fef052",
      "a77112b5512d4de4b9bf15a18525bd11",
      "18b192622fdf41a6a1f7ed74eddb5bd2",
      "678c10bee18d4343ac6c5fa0917c3c5d",
      "6fa53332abce490ca102ea1a08c728a3",
      "f8aac42851524236be2f567faf1373ae",
      "a6c6e0756565491994cfb5e0434529ef",
      "66c54e90cb6e48b581b6adfa2a98d30b",
      "e94139e6b50343cb9ef2d0c8bf6a99d5",
      "bc2b4f05d92d4285a6e9e2eee369f73c",
      "4b126ef5bb7d40fa87e4cc8173b7164d",
      "a1c16a7e2e8a4474802aca9a5b0fe8ac",
      "48b70a677c5143a68f7b27860faf80b5",
      "3ad297aeed8748a1ab2a295b7ce3ed53",
      "dc963bb73248457d822c135e70a05234",
      "6133cc18dcc94a67ba8f184e08ab83b7",
      "166b4670f5b0471d8d37f524ff16f4f5",
      "1d01c75df9e74bc2984eaa264d7ecb6c",
      "550741a8c67e480486b1ab2f975b50d8",
      "96d2c48680244c9098749e4640aeba84",
      "024e6637b26e42ea828e3dfebff62212",
      "029f2a1c0b2a443a8639bb6d5095989b",
      "123da41ab5d14cc0b691f2b18dbc378a",
      "aabbf8c7a98e4bc08bd7c75175e06d4e",
      "4076b4cc27614498b44b163a045f16a7",
      "1151aa668ac147c4b488cfaee5e2cb0c",
      "00c086f15f474cd6b37dd6b1c16c2246",
      "948ed2ba60b34fb9a11fdda57a2715e3",
      "20baa9e5917a41e483782f7f39d8d709",
      "6762cde151304d918706aa31e3935c75",
      "3c97b3c765fa4e3f8de663879fa5fe42",
      "94b193df703049aa9f99866eda5bf450",
      "8b9a55030caf4440b96f37398da3b0ec",
      "5405e3825f2540ffab90800ddf99ac70",
      "4c34067db03f47e8a1fe47311ebf298b",
      "12b2b33c8b8144599b4ac43bef8bca65",
      "5eca94c1cad84a86ac8d609ba072a808",
      "9abe26046bf24b3f821da4eeba954d8e",
      "c5a8099088f7497cb63eac77b8096682",
      "29b03ebd18ea43b4bb584fb0d0161d18",
      "045e434d2f544fec85c42b22d9e2a92e",
      "dbf3a0d51d034db68c5dc6d17879579b",
      "d4950e3f0adb4fc6a8d4a1775a0dc459",
      "33cef3e9834444c994776a2cfa087fb5",
      "ed7e85aa069d458caa24c6c10d1bf592",
      "90c8c71794584959a73b5736e380acd4",
      "dbbf68b20a0145e1a8a9364fb90cfe7b",
      "4fa29d09ecb84e339b3af599f5b1ffdf",
      "649ce5d6e36048bfa4a677dc291502f2",
      "0e0892ca01f4415fbcced05ae65be1c9",
      "15d56d458b48420fbe4ee4afe5505311",
      "be46ce6c18824ee1a58112bf12aabfd2",
      "6e52d6bc094143e095e596efe20193b0",
      "74bf9211d64541da959109af769b0b43",
      "177594ccb4fb4931bd857edd1bd69179",
      "aae7a792baf84d70bf795f1836386d1a",
      "e1991004369047c9b5dde48df014e575",
      "d8947a13827c4065943b0344d6addef0",
      "95412dd302344eadadfb5cfc2521025b",
      "8bb6785fa4c84a1eb09f1ad3cf124c64",
      "9b386dbb9c7846eaadab38b1392bc379",
      "33aa492091934a06b8a6db478f9a4d47",
      "ba3e99d3a9314c7fb2442ceca2f9b200",
      "7de8f5544dfc416e80c4a7ac7400f010",
      "e3605fe615844d188ce95da8cca4aa5c",
      "4214909ec6484ede81bb9cb317c41081",
      "d603d32c919f404c89553202d895ece9",
      "ea766ce8fb464989aaff5ad70cf7a214",
      "16174e954c7346e2921e6affd5c8bbfc",
      "e0c1183a0b6246b8b130b2ad2942142b",
      "927c052ae211446a950e25784a0634a9",
      "4d385cf740ce4ab0a24c04097269ca70",
      "20d04e9cfc6343c796d4c8e0561b4d3f",
      "97d56e9426a04a39b615ea2717b5aaee",
      "7a98e30fdc0b46d59f209bf27a3f893a",
      "c6403a6935764830983dc4411f07f463",
      "c8f0e5a4532d4e988852638ee6605b43",
      "4205280ab1924b2c929d592cf58417e4",
      "b9d2cc2a639641e98b3095f39c53d048",
      "dd4e7b6d13064b53bf26406955c5311f",
      "0401dec293cc4e6e87a36af0aba3917e",
      "eb6927d82140403d9c3ed4364eeb3219",
      "2fd4757b12fe4b15b01f4db30675fe88",
      "1aa0050a836e4be2bb24eb15d6c4cf95",
      "2a22791cbf744a15b1e80a4411af97df",
      "17df9ca269a94d66b683879d32cb4439",
      "ef3098980b934120adc347b501e87ef6",
      "1794ab4704ec4e16a603996f7848c052",
      "2e43effafdbf4a6a84a9ab2ad867890b",
      "8bd0f32cd45b4ce685856039de79af0d",
      "d1bfe156783c49319b1225b15f7e78e2",
      "b7d898a0dd8545368bfc3b4a3662e605",
      "a02feb4f602842aeac9aeb58e1f9fb49",
      "df262b69bb9a4585a19cf58422700c83",
      "2fce61ffae7c4a88a273ce513adc2d35",
      "8fe5af5c7d844387975f35765e0b2f1d",
      "0f65f5a99bf74897929300d224e904fe",
      "792f3ac142d043b29829d20abe249d3b",
      "827811eb025b407da04ebf289722c750",
      "f343a534cbc743cf8f68c6696f492301",
      "5b94356c72ab4fc089060d020f573a43"
     ]
    },
    "id": "2c5ed89c",
    "outputId": "7df84f45-7f7e-4b69-97e5-cd3e110acfbe"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"google/gemma-3-12b-it\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "id": "6343e390"
   },
   "source": [
    "#### Step 8: Ensuring that the model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8aKn4Y2LX-m",
    "outputId": "49fabe01-572c-4cc0-a23b-cb7db215cbe3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "\n",
    "# test prompt\n",
    "prompt = \"The capital of France is\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=20,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "decoded_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded_text)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "bd21a2f5"
   },
   "source": [
    "## FROM THIS STEP ON, COPY AND PASTE WHATEVER EXPERIMENT CELLS YOU NEED.\n",
    "\n",
    "Do remember to do this step first before uploading into Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "370e65c5"
   },
   "source": [
    "## LLM Consistency Testing with Mistral LLM\n",
    "\n",
    "This notebook contains code for testing code inconsistency in Mistral LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "id": "9eff811c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "id": "847501b0"
   },
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(curr_dir)\n",
    "proj_dir = os.path.dirname(parent_dir)\n",
    "sys.path.append(proj_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6RTTpieL8vD",
    "outputId": "4a08f702-e3f3-4bd8-b980-61b6fd825b6e"
   },
   "outputs": [],
   "source": [
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "60fab327"
   },
   "outputs": [],
   "source": [
    "from code_generation.code_generation_tester import CodeGenerationTester\n",
    "from code_generation.prompt_templates.prompt_template import OpenEndedPromptTemplate\n",
    "from utility.constants import BigCodeBench, HumanEval, LexicalMutations, SyntacticMutations, LogicalMutations, PromptTypes, CodeGeneration, ReasoningModels, NonReasoningModels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "9cc57730"
   },
   "source": [
    "# Declaring constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "id": "76fd1f92"
   },
   "outputs": [],
   "source": [
    "## Declaring Prompt Type Constants\n",
    "ZERO_SHOT = PromptTypes.ZERO_SHOT\n",
    "ONE_SHOT = PromptTypes.ONE_SHOT\n",
    "FEW_SHOT = PromptTypes.FEW_SHOT\n",
    "\n",
    "## Declaring Mutation Constants\n",
    "RANDOM_MUTATION = LexicalMutations.RANDOM\n",
    "SEQUENTIAL_MUTATION = LexicalMutations.SEQUENTIAL\n",
    "LITERAL_FORMAT = LexicalMutations.LITERAL_FORMAT\n",
    "\n",
    "## Declaring Benchmark Name Constants\n",
    "BIGCODEBENCH = BigCodeBench.NAME\n",
    "HUMANEVAL = HumanEval.NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XLw_wNT51KwW",
    "outputId": "e30cd057-ffcd-4b4f-82ea-e5929eff3729"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU memory before running the test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Check available memory\n",
    "print(f\"Available GPU memory: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnTjaleVgEeq",
    "outputId": "2633b24c-421f-4473-bf35-aa98c14a10db"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXRnelYXnrkp",
    "outputId": "ff73d7b5-ffeb-46cb-eff2-8acb22046726"
   },
   "outputs": [],
   "source": [
    "!pip install requests_mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "ZapxzS8G82Nu",
    "outputId": "a06e9940-ef7f-4700-f39f-bdb1f73d37b1"
   },
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e331268de99445ca8e3a2aa7221f3603",
      "4614300d438e4b6d97325e35d8d96d71",
      "eb7cda34610b436abae36ea491613deb",
      "2840a1c1fb3d437089fb7959b2f64e37",
      "21eda9127c9747768d17c0213733ef0f",
      "44e4c15b444745548ee5aeb066ce6c5e",
      "0081f83df30a4394949ef87a4251ff2b",
      "ddf34117ea0f4395b3931844b002ca9c",
      "971cbb4c94364c9b80de73f79b4956c2",
      "50b581e1fab64d769df17fb9045ec180",
      "8439802e07124babaece6b284748a9af"
     ]
    },
    "id": "6p7dvxaJppve",
    "outputId": "a41395b2-8fd6-44b2-9146-26910bdd7bad"
   },
   "outputs": [],
   "source": "import os\nimport shutil\nimport subprocess\n\nprompt_type = ONE_SHOT\nmodel_name = \"google/gemma-3-12b-it\"\n\ntask_set = BIGCODEBENCH\n\ntry:\n    llmtester = CodeGenerationTester(f\"{task_set}_Code_Generation\")\nexcept Exception as e:\n    print(f'llmtester could not launch due to the following error: {e}')\n\n\nresults_base_dir = os.path.join(proj_dir, f'results/code_generation/{model_name}')\nos.makedirs(results_base_dir, exist_ok=True)\n\nmutation_configs = [\n    [],\n    [RANDOM_MUTATION],\n    [SEQUENTIAL_MUTATION]\n]\n\nfor mutations in mutation_configs:\n    mutation_str = \"_\".join(mutations) if mutations else \"no_mutation\"\n\n    output_file_path = os.path.join(results_base_dir, f\"{task_set}_{prompt_type}_{mutation_str}.csv\")\n    drive_dst_dir = os.path.join(f\"/content/drive/MyDrive/your-repo/code_generation/\", model_name)\n    drive_dst = os.path.join(drive_dst_dir, f\"{task_set}_{prompt_type}_{mutation_str}.csv\")\n\n    # Ensure Drive folder exists\n    os.makedirs(drive_dst_dir, exist_ok=True)\n\n    # Run experiment\n    llmtester.run_code_generation_test(\n    prompt_helper = OpenEndedPromptTemplate.return_model_appropriate_prompt(prompt_type, model_name),\n    num_tests=llmtester.question_database.count_documents({}),\n    mutations = mutations,\n    prompt_type= prompt_type,\n    output_file_path=output_file_path,\n    task_set = task_set,\n)\n\n    # Only copy if file exists\n    if os.path.exists(output_file_path):\n      shutil.copy(output_file_path, drive_dst)\n      print(f\"Saved {mutation_str} results to Drive: {drive_dst}\")\n    else:\n      print(f\"Output file not created: {output_file_path}\")"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}