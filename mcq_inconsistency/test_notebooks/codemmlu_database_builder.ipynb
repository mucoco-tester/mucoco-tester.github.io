{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## MongoDB MCQ Inconsistency Database Builder\n",
    "\n",
    "This notebook builds the MCQ Inconsistency database using the CodeMMLU benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import string\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "par_dir = os.path.dirname(curr_dir)\n",
    "proj_dir = os.path.dirname(par_dir)\n",
    "sys.path.append(proj_dir)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import MongoDBHelper\n",
    "from mcq_inconsistency.utility.codemmlu_helper import CodeGenerationCodeMMLUHelper\n",
    "from utility.constants import CodeMMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = MongoDBHelper(max_retries = 5)\n",
    "if db.check_database_connectivity():\n",
    "    print(\"MongoDB connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_qns_db = db.client[os.getenv('MONGODB_BENCHMARK_DATABASE')]\n",
    "codemmlu_database = pd.read_csv(\n",
    "    os.path.join(proj_dir, \"datasets/open_ended_format/codemmlu_test.csv\"),\n",
    "    encoding=\"utf-8\",\n",
    "    header=0,\n",
    "    )\n",
    "\n",
    "humaneval_database = pd.read_csv(\n",
    "    os.path.join(proj_dir, \"datasets/open_ended_format/humaneval_test_modified_open.csv\"),\n",
    "    encoding=\"utf-8\",\n",
    "    header=0,\n",
    "    quoting=1,           \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "codemmlu_task = CodeMMLU.Tasks.CODE_COMPLETION\n",
    "mcq_question_database = base_qns_db[os.getenv(\"MONGODB_CODEMMLU_COLLECTION\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_dict = {\n",
    "    \"A\" : 0,\n",
    "    \"B\" : 1,\n",
    "    \"C\" : 2,\n",
    "    \"D\" : 3,\n",
    "}\n",
    "\n",
    "failed_to_upload = []\n",
    "num_failed = 0\n",
    "\n",
    "for i in tqdm(range(\n",
    "    len(codemmlu_database)\n",
    "    )):\n",
    "    try:\n",
    "        input_task_id = f\"CodeMMLUMCQ{i - num_failed}\"\n",
    "\n",
    "        codemmlu_qn = codemmlu_database.iloc[i]\n",
    "        question = codemmlu_qn['question']\n",
    "        choices = codemmlu_qn['choices']\n",
    "        expected_ans = codemmlu_qn['answer']\n",
    "        original_id = codemmlu_qn['task_id']\n",
    "\n",
    "        humaneval_qn = humaneval_database.iloc[i]\n",
    "        test_suite = humaneval_qn['test']\n",
    "        func_name = humaneval_qn['entry_point']\n",
    "        humaneval_id = humaneval_qn['task_id']\n",
    "\n",
    "        if isinstance(choices, str):\n",
    "            choices = eval(choices)\n",
    "\n",
    "        question, qn_desc = CodeGenerationCodeMMLUHelper.seperate_original_desciptions(question)\n",
    "        qn_desc, examples = CodeGenerationCodeMMLUHelper.extract_examples(qn_desc)\n",
    "        choices = [CodeGenerationCodeMMLUHelper._standardize_leading_whitespaces(choice) for choice in choices ]\n",
    "\n",
    "        correct_choice = choices[ans_dict[expected_ans]]\n",
    "\n",
    "        full_sol = question + \"\\n\" + correct_choice\n",
    "\n",
    "        #sanity check for codemmlu full solution\n",
    "        test_suite = CodeGenerationCodeMMLUHelper.process_original_tests(test_suite)\n",
    "\n",
    "        validate_full_sol = CodeGenerationCodeMMLUHelper.check_test_case(\n",
    "            test_case = test_suite,\n",
    "            code_snippet = full_sol,\n",
    "            func_name = func_name\n",
    "        )\n",
    "\n",
    "        if not validate_full_sol:\n",
    "            failed_to_upload.append(original_id)\n",
    "            raise ValueError(\"Full Solution failed the test suite\")\n",
    "        \n",
    "        ## Checking through other choices to ensure that they do NOT pass the check function        \n",
    "        choice_dict = {}\n",
    "\n",
    "        for idx, choice in enumerate(choices):\n",
    "            choice_dict[string.ascii_uppercase[idx]] = choice\n",
    "        \n",
    "        keys_to_rem = []\n",
    "\n",
    "        for key, choice in choice_dict.items():\n",
    "            if key == expected_ans:\n",
    "                continue\n",
    "            \n",
    "            test_sol = question + \"\\n\" + choice\n",
    "\n",
    "            try:\n",
    "                multiprocessing_queue = multiprocessing.Queue()\n",
    "\n",
    "                verify_answer_process = multiprocessing.Process(        \n",
    "                target= CodeGenerationCodeMMLUHelper.run_llm_answer,\n",
    "                args = (test_sol, test_suite, func_name, multiprocessing_queue)\n",
    "                )\n",
    "\n",
    "                verify_answer_process.start()\n",
    "                verify_answer_process.join(timeout=5)\n",
    "\n",
    "                if verify_answer_process.is_alive():\n",
    "                    verify_answer_process.kill()\n",
    "                    verify_answer_process.join()\n",
    "                    raise RuntimeError(\"The mutated answer took too long to run, which could inidicate some sort of infinite loop\")\n",
    "\n",
    "                if not multiprocessing_queue.empty():\n",
    "                    error = multiprocessing_queue.get()\n",
    "                    raise error\n",
    "                \n",
    "                keys_to_rem.append(key)\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                print(f\"{input_task_id}: Option {key} ran for too long\")\n",
    "                continue\n",
    "\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        for key in keys_to_rem:\n",
    "            if key < expected_ans:\n",
    "                expected_ans = chr(ord(expected_ans)-1)\n",
    "            del choice_dict[key]\n",
    "\n",
    "        idx = 0\n",
    "        new_dict = {}\n",
    "        for key, choice in choice_dict.items():\n",
    "            new_key = string.ascii_uppercase[idx]\n",
    "            new_dict[new_key] = choice\n",
    "            idx += 1\n",
    "        \n",
    "\n",
    "        if len(choice_dict.keys()) <= 1:\n",
    "            num_failed += 1\n",
    "            print(f\"{original_id} was not uploaded as it only had 1 valid choice left.\")\n",
    "            continue\n",
    "\n",
    "        database_entry = {\n",
    "            \"_id\": input_task_id,\n",
    "            \"question\": question,\n",
    "            \"qn_desc\": qn_desc,\n",
    "            \"choices\": new_dict,\n",
    "            \"check\": test_suite,\n",
    "            \"answer\": expected_ans,\n",
    "            \"examples\": examples,\n",
    "            \"func_name\": func_name,\n",
    "            \"original_id\": original_id,\n",
    "            \"corresponding_humaneval_id\": humaneval_id\n",
    "        }\n",
    "\n",
    "        exisiting_entry = mcq_question_database.find_one({\"_id\": input_task_id})\n",
    "\n",
    "        if exisiting_entry is not None:\n",
    "            mcq_question_database.find_one_and_replace({\"_id\": input_task_id}, database_entry)\n",
    "        else:\n",
    "            mcq_question_database.insert_one(database_entry)\n",
    "        \n",
    "        ## Next, we need to ensure that the entry stored in the DB\n",
    "        db_entry = mcq_question_database.find_one(filter = {\"_id\": input_task_id})\n",
    "        \n",
    "        question = db_entry['question']\n",
    "        choices = db_entry['choices']\n",
    "        check = db_entry['check']\n",
    "        answer = db_entry['answer']\n",
    "        func_name = db_entry['func_name']\n",
    "\n",
    "        correct_choice = choices[answer]\n",
    "\n",
    "        full_sol = question + '\\n' + correct_choice\n",
    "\n",
    "        validate_full_sol = CodeGenerationCodeMMLUHelper.check_test_case(\n",
    "            test_case = test_suite,\n",
    "            code_snippet = full_sol,\n",
    "            func_name = func_name\n",
    "        )\n",
    "\n",
    "        if validate_full_sol is not True:\n",
    "            mcq_question_database.find_one_and_delete({\"_id\": input_task_id})\n",
    "            failed_to_upload.append(original_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(original_id, f\"failed to upload into the database due to following error: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(failed_to_upload) < 1:\n",
    "    print('All tasks uploaded successfully!')\n",
    "else:\n",
    "    print(f\"The following tasks failed: {failed_to_upload}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Notes: \n",
    "* Modified rt00012 answer from B to D. Original answer (B) was incorrect and D is correct.\n",
    "* Modified rt00052 examples by removing \">>> remove_vowels(\"abcdef\\nghijklm\")\" example. The \\n messes up the process\n",
    "* rt00067 to rt00164 examples are modified to doctest format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
