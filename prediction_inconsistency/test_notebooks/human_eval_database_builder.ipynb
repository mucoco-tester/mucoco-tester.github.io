{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## MongoDB HumanEval Prediction Inconsistency Database Builder\n",
    "\n",
    "This notebook is used to initialize a new prediction inconsistency database onto MongoDB for HumanEval benchmark.\n",
    "\n",
    "!!! Note: You **MUST** build the **Code Generation HumanEval**database before running this notebook as building the prediction inconsistency database relies on pre-processed data from there. Notebook for code generation HumanEval database is under `code_generation/test_notebooks/code_generation_test_notebook_humaneval.ipynb` from the project root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import copy\n",
    "from typing import List, Any\n",
    "import inspect\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "par_dir = os.path.dirname(curr_dir)\n",
    "proj_dir = os.path.dirname(par_dir)\n",
    "sys.path.append(proj_dir)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import MongoDBHelper\n",
    "from prediction_inconsistency.prediction_inconsistency_tester import PredictionInconsistencyHumanEvalHelper\n",
    "from code_mutation.mutation_functions import CodeMutator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = MongoDBHelper()\n",
    "if db.check_database_connectivity():\n",
    "    print(\"MongoDB connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_qns_db = db.client[os.getenv(\"MONGODB_BENCHMARK_DATABASE\")]\n",
    "question_database = base_qns_db[os.getenv(\"MONGODB_HUMANEVAL_CG_COLLECTION\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_question_database = base_qns_db[os.getenv('MONGODB_HUMANEVAL_IO_COLLECTION')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict\n",
    "class AST_Helper:\n",
    "\n",
    "    COMPARE_OP_MAP = {\n",
    "        ast.Eq: \"==\",\n",
    "        ast.NotEq: \"!=\",\n",
    "        ast.Lt: \"<\",\n",
    "        ast.LtE: \"<=\",\n",
    "        ast.Gt: \">\",\n",
    "        ast.GtE: \">=\",\n",
    "        ast.Is: \"is\",\n",
    "        ast.IsNot: \"is not\",\n",
    "        ast.In: \"in\",\n",
    "        ast.NotIn: \"not in\",\n",
    "    }\n",
    "\n",
    "    def route_ast_type(code: ast.AST):\n",
    "        if isinstance(code, ast.Call):\n",
    "            return AST_Helper.extract_ast_call_args(code)\n",
    "\n",
    "        elif isinstance(code, ast.Constant):\n",
    "            return AST_Helper.extract_ast_constant(code)\n",
    "        \n",
    "        elif isinstance(code, ast.UnaryOp):\n",
    "            return AST_Helper.extract_ast_unaryop(code)\n",
    "        \n",
    "        elif isinstance(code, ast.List):\n",
    "            return AST_Helper.extract_ast_list(code)\n",
    "        \n",
    "        elif isinstance(code, list):\n",
    "            res = [AST_Helper.route_ast_type(c) for c in code]\n",
    "            return res[0] if len(res) == 1 else res\n",
    "        \n",
    "        elif isinstance(code, ast.Tuple):\n",
    "            return AST_Helper.extract_ast_tuple(code)\n",
    "        \n",
    "        elif isinstance(code, ast.Dict):\n",
    "            return AST_Helper.extract_ast_dict(code)\n",
    "            \n",
    "        elif isinstance(code, ast.BinOp):\n",
    "            return AST_Helper.extract_ast_bin_op(code)\n",
    "        \n",
    "        elif isinstance(code, ast.Name):\n",
    "            return AST_Helper.extract_ast_name(code)\n",
    "        \n",
    "        elif isinstance(code, ast.operator):\n",
    "            if isinstance(code, ast.Mult):\n",
    "                return \"*\"\n",
    "            elif isinstance(code, ast.Sub):\n",
    "                return \"-\"\n",
    "            elif isinstance(code, ast.Div):\n",
    "                return \"/\"\n",
    "            elif isinstance(code, ast.Add):\n",
    "                return \"+\"\n",
    "            elif isinstance(code, ast.Pow):\n",
    "                return \"**\"\n",
    "            else:\n",
    "                raise ValueError(f\"A method to process {type(code)} operator type has not been developed\")\n",
    "        \n",
    "        elif not isinstance(code, ast.AST):\n",
    "            return code\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"A method to process {type(code)} has not been developed\")\n",
    "\n",
    "    def extract_ast_dict(code: ast.Dict) -> Dict[Any, Any]:\n",
    "        if isinstance(code, ast.Dict):\n",
    "            dict_values = code.values\n",
    "            dict_keys = code.keys\n",
    "            key_val_pairs = zip(dict_keys, dict_values)\n",
    "            res = {}\n",
    "            for pair in key_val_pairs:\n",
    "                res[AST_Helper.route_ast_type(pair[0])] = AST_Helper.route_ast_type(pair[1])\n",
    "            return res\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect extraction method used, code snippet is not ast.Dict type.\")\n",
    "\n",
    "    def extract_ast_call_args(code: ast.Call) -> Tuple[str, list[str]]:\n",
    "        if isinstance(code, ast.Call):\n",
    "            test_args = [AST_Helper.route_ast_type(arg) for arg in code.args]\n",
    "            if code.func.id not in dir(__builtins__):\n",
    "                args_meta_data = [type(arg).__name__ for arg in test_args]\n",
    "                return test_args[0] if len(test_args) == 1 else test_args, args_meta_data[0] if len(args_meta_data) == 1 else args_meta_data\n",
    "            else:\n",
    "                return test_args[0] if len(test_args) == 1 else test_args\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect extraction method used, code snippet is not ast.Call type.\")\n",
    "        \n",
    "    def extract_ast_constant(code: ast.Constant) -> str:\n",
    "        if isinstance(code, ast.Constant):\n",
    "            return code.value\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect extraction method used, code snippet is not ast.Constant type.\")\n",
    "    \n",
    "    def extract_ast_compare(code: ast.Compare) -> Tuple[Any, str | List[str], Any]:\n",
    "        if isinstance(code, ast.Compare):\n",
    "            left_side = code.left\n",
    "            if isinstance(left_side, ast.AST):\n",
    "                left = AST_Helper.route_ast_type(left_side)\n",
    "\n",
    "            comparators = AST_Helper.route_ast_type(code.comparators)\n",
    "\n",
    "            ops = [AST_Helper.COMPARE_OP_MAP[type(op)] for op in code.ops]                    # a list is used here as there could be more than 1 ops\n",
    "            \n",
    "            return (\n",
    "                left, \n",
    "                ops[0] if len(ops) == 1 else ops, \n",
    "                comparators\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Incorrect extraction method used, code snippet is not ast.Constant type.\")\n",
    "        \n",
    "    def extract_ast_tuple(code: ast.Tuple) -> Tuple[Any]:\n",
    "        if isinstance(code, ast.Tuple):\n",
    "            elts = code.elts\n",
    "            return tuple(AST_Helper.route_ast_type(elt) for elt in elts)\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect extraction method used, code snippet is not ast.Tuple type.\")\n",
    "    \n",
    "    def extract_ast_bin_op(code: ast.BinOp) -> int:\n",
    "        if isinstance(code, ast.BinOp):\n",
    "            left = AST_Helper.route_ast_type(code.left)\n",
    "            right = AST_Helper.route_ast_type(code.right)\n",
    "            oper = AST_Helper.route_ast_type(code.op)\n",
    "\n",
    "            def format_val(val):\n",
    "                return repr(val) if isinstance(val, str) else val\n",
    "            \n",
    "            return (eval(f\"{format_val(left)} {oper} {format_val(right)}\"))\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect extraction method used, code snippet is not ast.Tuple type.\")\n",
    "\n",
    "    def extract_ast_name(code: ast.Name) -> str:\n",
    "        if isinstance(code, ast.Name):\n",
    "            return code.id\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect extraction method used, code snippet is not ast.Name type.\")\n",
    "\n",
    "    def extract_ast_unaryop(code: ast.UnaryOp) -> int | float:\n",
    "        unary_map = {\n",
    "            ast.USub: \"-\",\n",
    "            ast.UAdd: \"+\",\n",
    "            ast.Not: \"not \",\n",
    "            ast.Invert: \"~\"\n",
    "        }\n",
    "        if isinstance(code, ast.UnaryOp):\n",
    "            symbol = unary_map[type(code.op)]\n",
    "            value = str(code.operand.value)\n",
    "            try:\n",
    "                return int(symbol + value)\n",
    "            except ValueError:\n",
    "                return float(symbol + value)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Unable to extract the unaryop due to the following error: {e}\")\n",
    "\n",
    "    def extract_ast_list(code: ast.List) -> List[Any]:\n",
    "        if isinstance(code, ast.List):\n",
    "            list_elements = code.elts\n",
    "            return [AST_Helper.route_ast_type(elt) for elt in list_elements]\n",
    "        else:\n",
    "            print(type(code))\n",
    "            raise ValueError(\"Incorrect extraction method used, code snippet is not ast.List type.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_assert_cases(code: str) -> Tuple[int, List, int]:\n",
    "    test_cases = []             # list storing the test parameters and test outputs for this check function\n",
    "    num_cases = 0               # integer storing the number of test cases in this check function\n",
    "    failed_cases = set()        # assert statements that failed to extract, if any\n",
    "    rejected_cases = 0           # rejected test cases as the assert statements do not check for \"==\"\n",
    "\n",
    "    tree = ast.parse(code)\n",
    "    for node in tree.body:\n",
    "        if not isinstance(node, ast.FunctionDef):\n",
    "            continue\n",
    "\n",
    "        for subnode in node.body:       #iterating through eachline node within the check function\n",
    "            if not isinstance(subnode, ast.Assert):\n",
    "                continue \n",
    "\n",
    "            test_expr = subnode.test\n",
    "            num_cases+= 1\n",
    "            test_outputs = None\n",
    "            test_params = None\n",
    "\n",
    "            if isinstance(test_expr, ast.Compare):\n",
    "                ### Extracts test cases such as \"assert candidate([1,2,3]) == 3\"\n",
    "                ops_type = test_expr.ops[0]                 # assuming only one operator in the assert case\n",
    "                if type(ops_type) != ast.Eq:                # test case rejected as it is not check for equivalence\n",
    "                    rejected_cases += 1\n",
    "                    num_cases -= 1                          # not collecting comparisons with \"<\", \">\", etc as test cases\n",
    "                    continue\n",
    "                else:\n",
    "                    test_params, test_operators, test_outputs = AST_Helper.extract_ast_compare(test_expr)\n",
    "            elif isinstance(test_expr, ast.Call):\n",
    "                ### Extracts test cases such as assert candidate([1,2,3]) \n",
    "                test_params = AST_Helper.extract_ast_call_args(test_expr)\n",
    "                test_outputs = True\n",
    "\n",
    "            elif isinstance(test_expr, ast.UnaryOp):\n",
    "                ### Extracts test cases such as assert not candidate([1,2,3])\n",
    "                op = test_expr.op\n",
    "                operand = test_expr.operand\n",
    "                test_params = AST_Helper.route_ast_type(operand)\n",
    "                if isinstance(op, ast.Not):\n",
    "                    test_outputs = False \n",
    "                else: \n",
    "                    failed_cases.add(num_cases-1)\n",
    "                \n",
    "            elif isinstance(test_expr, ast.Constant):\n",
    "                ### Ignores test cases such as assert True\n",
    "                num_cases -= 1\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Can't decide: \", type(test_expr))\n",
    "                continue\n",
    "                \n",
    "            test_cases.append((test_params, test_outputs))\n",
    "                \n",
    "        \n",
    "    return num_cases, test_cases, rejected_cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = set()\n",
    "tot = 0\n",
    "repurposed_qn = {}\n",
    "rej_tot = 0\n",
    "for i in tqdm(range(\n",
    "    question_database.count_documents({})\n",
    "    )):\n",
    "    task_id = f\"HumanEvalo{i}\"\n",
    "    sample_qn = question_database.find_one({\"_id\" : task_id})\n",
    "    qn = sample_qn['qn']\n",
    "    qn_desc = sample_qn['qn_desc']\n",
    "    examples = sample_qn['examples']\n",
    "    canon_sol = sample_qn['canon_solution']\n",
    "    check = sample_qn['check']\n",
    "    original_id = sample_qn['original_id']\n",
    "    func_name = sample_qn['func_name']\n",
    "\n",
    "    complete_sol = qn + '\\n' + canon_sol\n",
    "\n",
    "    try:\n",
    "        num_cases, test_cases, rejected_cases = extract_assert_cases(check)\n",
    "        if num_cases != len(test_cases):\n",
    "            print(f\"{task_id}: num cases = {num_cases}, test cases extracted = {test_cases}\")\n",
    "        tot += num_cases\n",
    "        rej_tot += rejected_cases\n",
    "        if len(test_cases) < 1:\n",
    "            c.add(task_id)\n",
    "        else:\n",
    "            repurposed_qn[task_id] = test_cases\n",
    "\n",
    "    except Exception as e:\n",
    "        print(task_id)\n",
    "        print(f\"Failed due to following error: {e}\")\n",
    "\n",
    "    for idx, test_case_details in enumerate(test_cases):\n",
    "        test_case_id = f\"HumanEvalTF{tot - len(test_cases) + idx}\"\n",
    "\n",
    "        test_case, expected_output = test_case_details\n",
    "        test_input, args_meta_data = test_case\n",
    "\n",
    "        namespace = {}\n",
    "\n",
    "        exec(complete_sol, namespace)\n",
    "\n",
    "        sig = inspect.signature(namespace[func_name])\n",
    "        input_copy = copy.deepcopy(test_input) if isinstance(test_input, (list, dict, set, tuple)) else test_input\n",
    "\n",
    "        try:\n",
    "            if len(sig.parameters) > 1 and isinstance(test_input, list):\n",
    "                assert namespace[func_name](*input_copy) == expected_output\n",
    "            else:\n",
    "                assert namespace[func_name](input_copy) == expected_output\n",
    "\n",
    "        except:\n",
    "            print(f\"Did not pass test case. Double check task_id {task_id}, test_case {test_input}\")\n",
    "\n",
    "        input_metadata = type(test_input).__name__\n",
    "\n",
    "        func_in_input = None\n",
    "        \n",
    "        if isinstance(test_input, dict):\n",
    "            test_input = str(test_input)\n",
    "        elif isinstance(test_input, (tuple, list)):\n",
    "            test_input = str(test_input) if any(i for i in test_input if isinstance(i, dict)) else test_input\n",
    "\n",
    "        ### Storing / updating entry in the database\n",
    "        db_entry = {\n",
    "            \"_id\" : test_case_id,\n",
    "            \"full_sol\" : complete_sol,\n",
    "            \"qn_desc\": qn_desc,\n",
    "            \"input\" : {\n",
    "                \"args\": test_input,\n",
    "                \"metadata\": args_meta_data,\n",
    "                },\n",
    "            \"output\": {\n",
    "                \"args\" : str(expected_output),\n",
    "                \"metadata\": type(expected_output).__name__,\n",
    "                },\n",
    "            \"examples\": examples,\n",
    "            \"original_id\": original_id,\n",
    "            \"func_name\": func_name\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            tf_question_database.update_one(\n",
    "                filter={\"_id\": test_case_id},\n",
    "                update={\"$set\": db_entry},\n",
    "                upsert=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Could not enter test case {test_case_id} into TF database due to the following error: {e}\")\n",
    "            print(f\"Testcase: {test_case}\")\n",
    "\n",
    "\n",
    "        ## Secondary check where the question is pulled from the database and tested against the check function\n",
    "        ## This step is necessary as MongoDB does not store these details in standard Python data formats and a secondary step is needed for sanity check. \n",
    "        ## For example, tuples are stored as \"arrays\" in MongoDB, which are converted to Lists in Python.\n",
    "        \n",
    "        qn = tf_question_database.find_one({\"_id\" : test_case_id})\n",
    "        if qn is None:\n",
    "            continue\n",
    "        full_sol = qn['full_sol']                           # full canonical solution for the task\n",
    "        examples = qn['examples']                           # examples for other prompt techniques like one shot, few shot\n",
    "\n",
    "        test_inputs = qn['input']                           # unpacking input args and metadata from qn\n",
    "        input_args = test_inputs['args']                    # test input args\n",
    "        input_metadata = test_inputs['metadata']            # test input metadata\n",
    "\n",
    "        test_outputs = qn['output']                         # unpacking outputs args and metadata from qn\n",
    "        output_args = test_outputs['args']                  # test output args\n",
    "        output_metadata = test_outputs['metadata']          # test output metadata\n",
    "        func_name = qn['func_name']\n",
    "\n",
    "        try:\n",
    "            input_args = eval(input_args) if isinstance(input_args, str) and input_metadata != str.__name__  else input_args\n",
    "        except Exception as e:\n",
    "            print(input_metadata)\n",
    "            print(original_id)\n",
    "            print(e)\n",
    "            continue\n",
    "        \n",
    "        ## Processing of output args and metadata\n",
    "        output_args = ast.literal_eval(output_args) if output_metadata != str.__name__ else output_args\n",
    "\n",
    "        check_stored_soln_validity = PredictionInconsistencyHumanEvalHelper.check_input_output(\n",
    "            full_sol= full_sol,\n",
    "            test_input= copy.deepcopy(input_args),\n",
    "            expected_output= output_args,\n",
    "            func_name=func_name,\n",
    "            input_metadata = input_metadata\n",
    "        )\n",
    "\n",
    "        if check_stored_soln_validity is not True:\n",
    "            tf_question_database.find_one_and_delete({\"_id\" : task_id})\n",
    "            print(f'{test_case_id} from {task_id} failed the secondary checks and was not added to the database.')\n",
    "            tot-=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{tf_question_database.count_documents({})} total test cases in the database\")\n",
    "print(f'{tot} valid test cases successfully stored in MongoDB')\n",
    "print(f'{rej_tot} test cases were rejected')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
