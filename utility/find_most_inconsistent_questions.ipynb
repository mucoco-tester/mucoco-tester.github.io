{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_two_df(df1: pd.DataFrame, df2: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    common_ids = set(df1[\"task_id\"]) & set(df2[\"task_id\"])\n",
    "    if not common_ids:\n",
    "        print(\"⚠️ No matching task_ids found between the two DataFrames.\")\n",
    "        return df1.iloc[0:0], df2.iloc[0:0]  # return empty aligned frames\n",
    "\n",
    "    df1_filtered = df1[df1[\"task_id\"].isin(common_ids)].copy()\n",
    "    df2_filtered = df2[df2[\"task_id\"].isin(common_ids)].copy()\n",
    "\n",
    "    df1_filtered = df1_filtered.drop_duplicates(subset=[\"task_id\"], keep=\"first\")\n",
    "    df2_filtered = df2_filtered.drop_duplicates(subset=[\"task_id\"], keep=\"first\")\n",
    "\n",
    "    df1_filtered = df1_filtered.sort_values(\"task_id\").reset_index(drop=True)\n",
    "    df2_filtered = df2_filtered.sort_values(\"task_id\").reset_index(drop=True)\n",
    "\n",
    "    return df1_filtered, df2_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid_failure(failure: str):\n",
    "    if isinstance(failure, float) or (isinstance(failure, str) and \"AssertionError\" in failure and \"Mutation\" not in failure):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = \"RESULT_FILE_PATH\"\n",
    "benchmark  = \"CruxEval\"\n",
    "mutations = [\"for2while\", \"for2enumerate\", \"boolean_literal\", \"commutative_reorder\", \"constant_unfold_add\", \"constant_unfold\", \"constant_unfold_mult\", \"demorgan\", \"literal_format\", \"random\", \"sequential\" ]\n",
    "\n",
    "res_dict = {}\n",
    "\n",
    "for models in os.listdir(res_dir):\n",
    "\n",
    "    if 'ensemble' in models or \".DS_Store\" in models:\n",
    "        continue\n",
    "\n",
    "    model_res_dir = os.path.join(res_dir, models)\n",
    "    no_mut_name = [res for res in os.listdir(model_res_dir) if \"no_mutation\" in res and benchmark in res][-1]\n",
    "    no_mut_res_dir = os.path.join(model_res_dir, no_mut_name)\n",
    "    no_mut_data = pd.read_csv(no_mut_res_dir)\n",
    "\n",
    "    for res_csv in os.listdir(model_res_dir):\n",
    "        if benchmark not in res_csv or \"ensemble\" in res_csv:\n",
    "            continue\n",
    "        for mutation in mutations:\n",
    "            mutation_df = res_dict.get(mutation, pd.DataFrame())\n",
    "\n",
    "            base_name = os.path.splitext(res_csv)[0]\n",
    "            parts = base_name.split(\"_\")\n",
    "\n",
    "            if parts[-1] in mutation.split('_')[-1]:\n",
    "                mut_data = pd.read_csv(os.path.join(model_res_dir, res_csv))\n",
    "\n",
    "                mut_data_copy = mut_data.copy()\n",
    "                no_mut_data_copy = no_mut_data.copy()\n",
    "\n",
    "\n",
    "                mut_failures = mut_data_copy.loc[:, \"failure_type\"]\n",
    "                mut_failures.name = f\"failure_type_{models}_{mutation}\"\n",
    "                \n",
    "\n",
    "                no_mut_failures = no_mut_data_copy.loc[:, \"failure_type\"]\n",
    "                no_mut_failures.name = f\"failure_type_{models}_no_mut\"\n",
    "\n",
    "\n",
    "                mask = ~(\n",
    "                    no_mut_failures.str.contains(\"AssertionError\", na=False)\n",
    "                    & mut_failures.str.contains(\"AssertionError\", na=False)\n",
    "                )\n",
    "\n",
    "                no_mut_failures = no_mut_failures[mask]\n",
    "                mut_failures = mut_failures[mask]\n",
    "\n",
    "                # Concatenate SIDE BY SIDE\n",
    "                mutation_df = pd.concat([mutation_df, no_mut_failures, mut_failures], axis=1)\n",
    "                def custom_sort_key(col_name: str) -> tuple:\n",
    "                    if \"gpt-4o\" in col_name.lower():\n",
    "                        return (0, col_name.lower())\n",
    "                    elif \"gpt-5\" in col_name.lower():\n",
    "                        return (1, col_name.lower())\n",
    "                    elif \"qwen\" in col_name.lower():\n",
    "                        return (2, col_name.lower())\n",
    "                    elif \"llama\" in col_name.lower():\n",
    "                        return (3, col_name.lower())\n",
    "                    elif \"gemma\" in col_name.lower():\n",
    "                        return (4, col_name.lower())\n",
    "                    elif \"deepseek\" in col_name.lower():\n",
    "                        return (5, col_name.lower())\n",
    "                    elif \"codestral\" in col_name.lower():\n",
    "                        return (6, col_name.lower())\n",
    "                    else:\n",
    "                        return (7, col_name.lower())\n",
    "                    \n",
    "                sorted_cols = sorted(mutation_df.columns, key=custom_sort_key)\n",
    "                mutation_df = mutation_df.reindex(columns=sorted_cols)\n",
    "                res_dict[mutation] = mutation_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(res_dict)\n",
    "os.makedirs(\"temp_res2\", exist_ok=True)\n",
    "for key, df in res_dict.items():\n",
    "    df.to_csv(f\"temp_res2/{key}.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
